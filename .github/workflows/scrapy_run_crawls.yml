name: Scrapy General Point

on:
  schedule:
    - cron: '0 17 * * *'
  workflow_dispatch:

permissions:
  contents: read

env:
  PYTHON_VERSION: "3.11"
  POETRY_VERSION: "1.4.2"
  POETRY_URL: https://install.python-poetry.org

jobs:
  use_cache:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
        id: setup_python
      # Poetry cache depends on OS, Python version and Poetry version.
      - name: Cache Poetry cache
        uses: actions/cache@v3
        with:
          path: ~/.cache/pypoetry
          key: poetry-cache-${{ runner.os }}-${{ steps.setup_python.outputs.python-version }}-${{ env.POETRY_VERSION }}
      # virtualenv cache should depends on OS, Python version and `poetry.lock` (and optionally workflow files).
      - name: Cache Packages
        uses: actions/cache@v3
        with:
          path: ~/.local
          key: poetry-local-${{ runner.os }}-${{ steps.setup_python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}-${{ hashFiles('.github/workflows/*.yml') }}
      - name: Install Poetry ${{ env.POETRY_VERSION }}
        run: |
          curl -sSL ${{ env.POETRY_URL }} | python - --version ${{ env.POETRY_VERSION }}
          echo "$HOME/.local/bin" >> $GITHUB_PATH
      - name: Install Dependencies
        run: poetry install

      - name: Run the automated crawlers
        run: poetry run scrapy_crawlers 
